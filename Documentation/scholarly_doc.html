<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <!--responsive-->
        <title>Documentația proiectului</title>
        <link href="scholarly_doc.css" rel="stylesheet">
        <style>
            img {
            margin-left: 0;

            border: 1px solid #ffffff;
            align-self: center;
            }
        </style>
    </head>
    <body prefix="schema: http://schema.org">
        <article typeof="schema:ScholarlyArticle" resource="#">
            <header>
                <h1>Job Hunter</h1>
            </header>
            <div role="contentinfo">
                <section typeof="sa:AuthorsList">
                    <h2>Authors</h2>
                    <ul>
                        <li typeof="sa:ContributorRole" property="schema:author">
                            <span typeof="schema:Person">
                                <meta property="schema:givenName" content="Ana">
                                <meta property="schema:familyName" content="Ciobanu">
                                <span property="schema:name">Ciobanu Ana</span>
                            </span>
                        </li>
                        <li typeof="sa:ContributorRole" property="schema:author">
                            <span typeof="schema:Person">
                                <meta property="schema:givenName" content="Maria-Magdalena">
                                <meta property="schema:familyName" content="Roca">
                                <span property="schema:name">Roca Maria-Magdalena</span>
                            </span>
                        </li>
                    </ul>
                </section>
            </div>
            <section id="introduction" role="doc-introduction">
                <h2>1.Introduction</h2>
                <section>
                    <h3>1.1 Purpose of the Report</h3>
                    <p>
                        The purpose of this report is to give you information and guidance on
                        the implementation, functionalities and usage of
                        an app that provide different services.
                        The app stores, manipulates and displays information on the jobs and events from IT domain,
                        giving the users possibility to view, filter, visualize and get suggestions based on their preferences.
                    </p>
                </section>
                <section>
                    <h3>1.2 Scope of the Report</h3>
                    <p>
                      This report provides an in-depth overview of the application designed to assist job seekers
                       in finding relevant job opportunities and events. The app also helps users understand the current job 
                       market and search jobs based on location by exploring the interactive map, also events based on multiple criteria.

                      The report covers the key components of the application, including its user interface, backend 
                      infrastructure, and data processing mechanisms. It details how job listings and events are sourced,
                       processed, and presented to users. Additionally, the report outlines the technologies used, the data
                        flow architecture, and the recommendation system that enhances user experience.
                    </p>
                </section>
            </section>
            <section>
                <h2>2.Overall Description</h2>
                <section>
                    <h3>2.1 Product Functions</h3>
                    <p>
                      Major features of our program available for users include:
                        <ol>
                          <li>Filter events</li>
                          <li>Visualization of events statistics</li>
                          <li>Explore jobs and events on a interacting map</li>
                        </ol>  
                        Major backend functions of our program include:
                        <ol>
                          <li>Data enrichement</li>
                          <li>Data processing</li>
                          <li>Triple insertion API</li>
                          <li>SPARQL Query Data APIs</li>
                          <li>Ontology creation</li>
                        </ol>                     

                </section>
                <section>
                    <h3>2.2 User Classes and Characteristics</h3>
                    <p>The program was designed to be used by an average user.
                      The functionalities are easy and straightforward,
                      so it is not needed any preliminary guidance. <br>
                      <b>- Frequency of use.</b> An average user should access the site twice per week to check for updates and new events or jobs he might be interested in.
                      <br>
                      <b>- Subset of product functions used.</b> The product has basic functions like browsing, filtering and visualization. For the general user they are easy to use.
                      <br>
                      <b>- Education level and expirience.</b> There is not much need for advanced knowledge in order to use the application, yet the app target audience are the persons who have studies in the IT domain or interested to learn about it and are looking for a new job in IT.
                      <br>

                    </p>
                </section>
                </section>
                <section id="architecture">
                  <h2>3. General architecture</h2>
                  <figure typeof="sa:Image">
                    <img src="documentation_images/bpmn.png"  width="880"
                    height="625" alt="" >
                    <figcaption>
                     Fig.Data processing component
                    </figcaption>
                  </figure>
                  <figure typeof="sa:Image">
                    <img src="documentation_images/useCaseDiagram.png"  width="880"
                    height="625" alt="" >
                    <figcaption>
                     Fig.Use case diagram
                    </figcaption>
                  </figure>
                </section>
                <section id="technical_aspects">
                  <h2>4. Technical aspects</h2>
                  <section>
                    <h3>4.1 Knowledge model</h3>
                    <h3>4.1.1 Ontology creation</h3>
                    <p>To better structure and represent data, we developed a domain-specific ontology using Protégé, a widely adopted ontology development tool. This ontology is designed to model job descriptions and IT-related events systematically, allowing for efficient data integration, retrieval, and reasoning.
                      The ontology defines several key classes, which can be seen in the next images.
                      <figure typeof="sa:Image">
                        <img src="documentation_images/ThingOwlViz.png"  width="700"
                        height="500" alt="" >
                        <figcaption>
                         Fig. Ontology part 1
                        </figcaption>
                      </figure>
                      <figure typeof="sa:Image">
                        <img src="documentation_images/SkillOwlViz.png"  width="880"
                        height="625" alt="" >
                        <figcaption>
                         Fig. Ontology part2
                        </figcaption>
                      </figure>
                      Each of these classes is linked through well-defined relationships. For example:
                      <ul>
                        <li>Job &rarr; requiresSkill &rarr; TechnicalSkill</li>
                        <li>Job &rarr; postedByCompany &rarr; Company</li>
                        <li>Event &rarr; takesPlaceIn &rarr; City</li>
                        <li>Event &rarr; hasTopic &rarr; Topic, TechnicalSkill</li>
                    </ul>
                      For each class there are specific data properties, such as eventDate(xsd:dateTime), eventType(xsd:string), isOnline(xsd:boolean).
                      By structuring job-related and IT event data through these semantic relationships, the ontology supports complex queries and facilitates meaningful insights.
                      <br>
                      The ontology follows key design patterns to ensure clarity and consistency:
                      <ul>
                          <li><strong>Class Hierarchy:</strong> The ontology maintains a structured hierarchy:
                              <ul>
                                  <li>Skill (superclass)
                                      <ul>
                                          <li>SoftSkill (disjoint with TechnicalSkill and LanguageSkill)</li>
                                          <li>TechnicalSkill
                                              <ul>
                                                  <li>ProgrammingLanguage (disjoint with Framework and Library)</li>
                                                  <li>Framework (disjoint with ProgrammingLanguage and Library)</li>
                                                  <li>Library (disjoint with ProgrammingLanguage and Framework)</li>
                                              </ul>
                                          </li>
                                          <li>LanguageSkill (disjoint with SoftSkill and TechnicalSkill)</li>
                                      </ul>
                                  </li>
                              </ul>
                          </li>
                          <li><strong>Disjoint Classes:</strong> The classes Framework, Library, and ProgrammingLanguage are explicitly disjoint, ensuring that an entity cannot belong to more than one of these categories. Similarly, SoftSkill, LanguageSkill, and TechnicalSkill are disjoint, preserving semantic clarity.</li>
                          <li><strong>Inverse Relations:</strong> The ontology incorporates inverse relationships, such as:
                              <ul>
                                  <li>Job → postedByCompany → Company</li>
                                  <li>Company → postedJob → Job</li>
                              </ul>
                          </li>
                          <li><strong>Object Properties with Specific Domains and Ranges:</strong>
                              <ul>
                                  <li>The use of Object Properties with specific rdfs:domain and rdfs:range constraints (e.g., requiresSkill, takesPlaceIn, and influencedBy) helps formalize relationships between different classes. These properties represent real-world relations like a job requiring a skill or an event taking place in a city.</li>
                              </ul>
                          </li>
                          <li><strong>Datatype Properties:</strong>
                              <ul>
                                  <li>Several Datatype Properties like jobTitle, companyName, datePosted, and experienceLevel are defined with appropriate domains and ranges (e.g., xsd:string, xsd:int). This pattern ensures that the ontology can handle data types in a structured and semantically consistent way.</li>
                              </ul>
                          </li>
                          <li><strong>Annotation Properties:</strong>
                              <ul>
                                  <li>While not explicitly shown, annotation properties such as rdfs:label or rdfs:comment provide human-readable descriptions. This pattern is important for enhancing the usability and understandability of the ontology.</li>
                              </ul>
                          </li>
                          <li><strong>Separation of Concerns:</strong>
                              <ul>
                                  <li>The ontology adheres to a separation of concerns by clearly dividing different concepts into distinct classes such as City, Country, Event, and Job. Each of these classes serves a specific role and helps maintain the clarity of the ontology, reducing complexity.</li>
                              </ul>
                          </li>
                      </ul>
                      <p>By structuring job-related and IT event data through these semantic relationships and ontology design patterns, the model supports complex queries and facilitates meaningful insights.</p>  
                    </p>

                    <h3>4.1.2 Pragmatic Use of Knowledge Sources</h3>
                    <p>To enhance the expressiveness and relevance of the ontology, we integrated external knowledge from Wikidata using SPARQL queries. Specifically, we enriched the <strong>TechnicalSkill</strong> class by classifying skills into Programming Languages, Frameworks, and Libraries using a structured query.</p>
                    <p>A representative SPARQL query dynamically categorizes a skill into one of these subclasses while retrieving additional relevant data:</p>
                    <pre>
                SELECT ?item ?influencedByLabel ?programmedInLabel ?officialWebsite ?type 
                ?description WHERE {
                  ?item (rdfs:label|skos:altLabel) "{skill_name}"@en.
                  ?item wdt:P31/wdt:P279* ?type.
                  OPTIONAL { ?item wdt:P737 ?influencedBy. }
                  OPTIONAL { ?item wdt:P277 ?programmedIn. }
                  OPTIONAL { ?item wdt:P856 ?officialWebsite. }
                  OPTIONAL {
                      ?item schema:description ?description.
                      FILTER(LANG(?description) = "en")
                  }
                  FILTER (?type IN (wd:Q9143, wd:Q29642950, wd:Q188860, wd:Q783866, wd:Q271680,
                   wd:Q1330336, wd:Q17155032, wd:Q506883, wd:Q7397, wd:Q110509708, wd:Q1130645))
                  SERVICE wikibase:label {
                    bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en".
                    ?influencedBy rdfs:label ?influencedByLabel.
                    ?programmedIn rdfs:label ?programmedInLabel.
                  }
                }
                    </pre>
                    <p>This query enables the system to:</p>
                    <ul>
                        <li>Identify whether a skill belongs to <strong>ProgrammingLanguage, Framework, or Library</strong>.</li>
                        <li>Retrieve external references such as the <strong>official website</strong>.</li>
                        <li>Extract metadata like <strong>influencedBy</strong> and <strong>programmedIn</strong> relationships.</li>
                    </ul>
                    <h3>4.1.3 Conformance to Linked Data Principles</h3>
                    <p>The system adheres to the Linked Data principles, ensuring interoperability and ease of data exchange.
                       The ontology and its concepts are stored in Apache Jena Fuseki, utilizing URIs with the prefix <http://www.semanticweb.org/ana/ontologies/2024/10/JobHunterOntology#>
                      To enable seamless data access, the ontology is hosted on an Apache Jena Fuseki server, 
                      which provides SPARQL endpoints for querying and retrieving data. Additionally, external resources,
                       such as Wikidata URIs, allow direct access to global knowledge graphs, enhancing data integration and reuse.
                      The ontology also establishes strong interlinks with external datasets. Job descriptions reference 
                      Wikidata skills, ensuring a standardized taxonomy for classification. Similarly, event data is linked to 
                      external event pages, promoting seamless integration with relevant datasets and knowledge bases.
                      For data representation and querying, the ontology relies on standardized formats such as RDF and OWL,
                       which define relationships and structure the ontology. The data is stored in Apache Jena Fuseki and 
                       queried using SPARQL, adhering to semantic web standards. Furthermore, relationships within the 
                       ontology are explicitly defined through properties like rdfs:label, ensuring human-readable descriptions.
                      By implementing these principles, the ontology guarantees scalability, interoperability, and consistency,
                       making it a robust solution for representing job listings and IT-related events while seamlessly
                        integrating with external knowledge sources.</p>
                    <h3>4.2 Data preparation</h3>
                    <h3>4.2.1 Data cleaning and normalization</h3>
                    <p>Since job listings came from various sources, certain data fields required preprocessing. Company names were
                       cleaned by removing special characters, trailing whitespace, and abbreviations like "LLC" or "Ltd."
                        Similarly, job titles were refined by extracting terms such as "remote" or "full-time" and storing
                         them separately in a designated field within the final JSON.</p>
                    <h3>4.2.2 Data extraction</h3>
                    <p>To extract information from job descriptions, we combined multiple techniques tailored to different 
                      types of data. For skills extraction, we utilized a skillNER python library specifically designed to 
                      identify and extract both technical and soft skills from unstructured text. Regular expressions were 
                      employed to identify structured details such as education fields and experience levels, ensuring 
                      precision in extracting these elements. For other data points, such as job locations, natural language 
                      processing (NLP) techniques and libraries (e.g., stanza) were applied to parse and extract relevant
                       information. This hybrid approach of combining specialized libraries, pattern matching, and NLP 
                       techniques ensured that the program could handle the diverse and often unstructured nature of job 
                       descriptions effectively.</p>
                       <figure typeof="sa:Image">
                        <img src="documentation_images/exJob.png"  width="880"
                        height="625" alt="" >
                        <figcaption>
                         Fig. JSON Job listing input
                        </figcaption>
                      </figure>
                      <figure typeof="sa:Image">
                        <img src="documentation_images/resultsExtraction.png"  width="880"
                        height="625" alt="" >
                        <figcaption>
                         Fig. Output data extraction
                        </figcaption>
                      </figure>
                    <h3>4.2.3 Data enrichement</h3>
                    <p>To enhance the extracted data, technical skills identified in the job descriptions were enriched
                       using Wikidata. Each skill was queried against Wikidata to retrieve additional information such as
                        its official website, influences, and other relevant properties. The technical skills were classified
                        into categories such as "Framework," "Library," or "Programming Language"using the query presented above(section 4.1.2).</p>
                        <figure typeof="sa:Image">
                          <img src="documentation_images/dataEnrichement.png"  width="700"
                          height="500" alt="" >
                          <figcaption>
                           Fig. Data enrichement of a technical skill
                          </figcaption>
                        </figure>
                    <h3>4.3 Triple Insertion API</h3>
                    <p><strong>Overview</strong></p>
                    <p>The Triple Insertion API is a RESTful service designed to convert structured job/event data into RDF triples compliant with the Job Hunter ontology and persist them into an Apache Jena Fuseki triplestore.</p>
                    <p>It acts as the bridge between raw data and semantic knowledge representation, ensuring data integrity and adherence to ontology constraints.</p>
                
                    <h3>Key Implementation Components</h3>
                
                    <h3>Endpoints</h3>
                    <ul>
                        <li><strong>POST /api/triples/store</strong>: Ingests job data (title, company, skills, etc.).</li>
                        <li><strong>POST /api/triples/storeEventTriple</strong>: Processes event data (title, location, topics, etc.).</li>
                    </ul>
                    <figure typeof="sa:Image">
                      <img src="documentation_images/api_triple_store.png"  width="700"
                      height="500" alt="" >
                      <figcaption>
                       Fig. Triple insertion API
                      </figcaption>
                    </figure>
                    <h3>1. Request Handling & Validation</h3>
                    <p>Uses Laravel’s Validator to enforce schema rules, ensuring required fields such as <code>jobTitle</code> and <code>eventDate</code> are present.</p>
                
                    <h3>2. Ontology Initialization</h3>
                    <h3>OntologyGenerator Class:</h3>
                    <p>Responsible for generating foundational ontology triples (classes, properties, hierarchies) on API startup.</p>
                    <p>It creates:</p>
                    <ul>
                        <li><strong>Classes</strong>: Job, Company, Skill, Event, City, etc.</li>
                        <li><strong>Object Properties</strong>: postedByCompany, requiresSkill, hasTopic.</li>
                        <li><strong>Data Properties</strong>: jobTitle, eventDate, isOnline.</li>
                    </ul>
                    <p>These triples are inserted into Fuseki first to ensure ontology consistency.</p>
                
                    <h3>3. Data-to-RDF Transformation</h3>
                    <h3>TripleService Class:</h3>
                
                    <h4>prepareIndividualTriples(array $data)</h4>
                    <p>Maps job data to RDF triples using the ontology.</p>
                    
                    <h4>Example Transformation for a Job:</h4>
                    <p><strong>Input:</strong></p>
                    <pre><code>{
                    "jobTitle": "Senior Developer",
                    "companyName": "Tech Corp"
                }</code></pre>
                
                    <p><strong>Output Triples:</strong></p>
                    <pre><code>&lt;{$baseUri}SeniorDeveloper&gt; rdf:type :Job ;
                                             :jobTitle "Senior Developer" ;
                                             :postedByCompany &lt;{$baseUri}TechCorp&gt; .</code></pre>
                
                    <p>Handles nested structures (e.g., skills, frameworks) by iterating through arrays and linking entities.</p>
                
                    <h4>prepareEventTriples(array $data)</h4>
                    <p>Similar logic applies for events, with additional handling for location (City/Country) and topics.</p>
                
                    <p><strong>Example Event Triple:</strong></p>
                    <pre><code>&lt;http://.../DevCon2024&gt; rdf:type :Event ;
                                        :eventTitle "DevCon 2024" ;
                                        :takesPlaceIn &lt;http://.../Cluj&gt; ;
                                        :hasTopic &lt;http://.../AI&gt; .</code></pre>
                
                    <h3>4. Batch Processing & SPARQL Insertion</h3>
                    <p>To avoid timeouts, large datasets are split into batches (e.g., 5 items/batch).</p>
                
                    <h3>Batch Processing Steps:</h3>
                    <ol>
                        <li>Execute Python script to classify skills.</li>
                        <li>Generate triples for jobs/events and their relationships.</li>
                        <li>Insert triples into Fuseki via SPARQL <code>INSERT DATA</code>.</li>
                    </ol>
                
                    <h3>Duplicate Prevention</h3>
                    <p>The method <code>TripleService::tripleExists()</code> checks for existing triples using SPARQL <code>ASK</code> queries before insertion.</p>
                
                    <h3>SPARQL Insert Example:</h3>
                    <pre><code>PREFIX : &lt;http://.../JobHunterOntology#&gt;
                INSERT DATA {
                    &lt;http://.../SeniorDeveloper&gt; :jobTitle "Senior Developer" ;
                                                  :postedByCompany &lt;http://.../TechCorp&gt; .
                }</code></pre>
                    <h3>4.4 SPARQL Query APIs</h3>
                    <h3>4.4.1 Events data query API</h3>
                    <p>The Events data query API is designed to be accessed by the frontend application to provide job seekers with relevant IT-related events. It allows users to filter events based on multiple criteria such as type, topic, location, and date.</p>
                    <figure typeof="sa:Image">
                      <img src="documentation_images/fastAPI.png"  width="700"
                      height="500" alt="" >
                      <figcaption>
                       Fig. Triple insertion API
                      </figcaption>
                    </figure>
                    <p>The API queries the Apache Jena Fuseki server and returns structured data in JSON format for display in the frontend.</p>
                    <h2>Query Formation & Filtering</h2>
                    <p>Each API call retrieves data from a Fuseki SPARQL database using a structured query. The queries follow a two-step process:</p>
                
                    <h3>Base Query</h3>
                    <p>Each query starts with a predefined SPARQL query, for example:</p>
                    <pre><code>SELECT ?eventTitle ?eventType ?topic ?isOnline ?date ?eventURL WHERE {
                    ?event rdf:type :Event ;
                           :eventTitle ?eventTitle;
                           :eventType ?eventType;
                           :hasTopic ?topic;
                           :isOnline ?isOnline;
                           :eventURL ?eventURL;
                           :eventDate ?date.
                }</code></pre>
                
                    <h3>Dynamic Filters</h3>
                    <p>Based on the request parameters, additional <code>FILTER</code> conditions or <code>VALUES</code> clauses are appended to refine the results.</p>
                
                    <p>If the request includes a filter for <strong>event type</strong>, the query is extended:</p>
                    <pre><code>VALUES ?eventType { "Conference" "Meetup" }</code></pre>
                
                    <p>If the request includes a filter for <strong>topics</strong>, the query is extended:</p>
                    <pre><code>VALUES ?topic { &lt;http://www.semanticweb.org/ana/ontologies/2024/10/JobHunterOntology#AI&gt; &lt;http://www.semanticweb.org/ana/ontologies/2024/10/JobHunterOntology#Cloud&gt; }</code></pre>
                
                    <p>If filtering by <strong>location</strong>, an additional condition is added:</p>
                    <pre><code>VALUES ?location { :Iasi :Bucharest }</code></pre>
                
                    <p>If filtering by <strong>date</strong>, a condition ensures only events on those dates are included:</p>
                    <pre><code>FILTER(str(?date) = "2024-05-01")</code></pre>
                
                    <h3>Handling Online/Offline Events</h3>
                    <ul>
                        <li>If an event is <strong>online</strong>, a specific base query is used that excludes location.</li>
                        <li>If an event is <strong>offline</strong>, a different base query includes location filtering.</li>
                        <li>If no online filter is provided, two queries are executed—one for online events and one for offline events—and the results are merged.</li>
                    </ul>
                
                    <h3>Data Source & Authentication</h3>
                    <p>The API retrieves data from a Fuseki SPARQL database using authenticated queries.</p>
                    <p>Environment variables are used to store sensitive credentials such as the API URL, username, and password.</p>
                
                    <h3>Frontend Integration</h3>
                    <p>The API is <strong>designed to be consumed by the frontend</strong>, which uses it to display events from Tech domain dynamically.</p>
                    <ul>
                        <li>The frontend makes requests with user-selected filters, and the API constructs SPARQL queries accordingly.</li>
                        <li>The returned JSON is formatted for easy consumption by charts, tables, and other UI components.</li>
                    </ul>
                    <figure typeof="sa:Image">
                      <img src="documentation_images/apiExample.png"  width="700"
                      height="500" alt="" >
                      <figcaption>
                       Fig. Get events API
                      </figcaption>
                    </figure>
                    <h3>4.4.2 Job query API</h3>
                    <p>Job Query API enables users to retrieve job listings from the triplestore based on dynamic filters such as date posted, experience level, location, criteria defined in the Job Hunter ontology. These queries leverage SPARQL’s flexibility to traverse RDF relationships and filter results semantically.

                      Queries are dynamically constructed using the ontology’s classes and properties. A base template ensures consistency while allowing parameterization:
                      The /api/map-data API executes generic queries, returning JSON response. 
                      </p>
                      <figure typeof="sa:Image">
                        <img src="documentation_images/apiMap.png"  width="700"
                        height="500" alt="" >
                        <figcaption>
                         Fig. API for map data
                        </figcaption>
                      </figure>
                    <h3>4.4.3 Event query API for map</h3>
                    <p>The /api/events-map-data retrieves IT events by topic, date, or location.
                      These last endpoints are used in displaying jobs and events on the map.
                      
                      
                      MapPage Implementation
                      
                      The MapPage implementation is a React-based interactive map that displays both job and event locations retrieved from an API. It utilizes the Leaflet library for mapping functionalities, supports marker clustering, and includes a search control for enhanced user interaction.
                      
                      This report details the technologies used, data processing, and key implementation aspects that make the map efficient and user-friendly.
                      
                      1 Technologies & Libraries Used
                      Frontend Framework
                      React.js – Used to build a modular and efficient UI.
                      React Bootstrap – Provides responsive UI components like containers, rows, and cards.
                      React Router DOM – Handles page navigation.
                      Data Fetching & State Management
                      Axios – Used to fetch data from API endpoints asynchronously.
                      useState & useEffect (React Hooks) – Manage component state and trigger API requests on mount.
                      Mapping Library
                      Leaflet.js – The main library used for rendering the interactive map.
                      Leaflet.markercluster – Enables clustering of markers to improve map readability.
                      Leaflet-geosearch – Provides a search bar for users to find locations.
                      Styling & UI Enhancements
                      CSS – Custom styling for map and loading state.
                      
                      2 Implementation Details
                      
                      The implementation fetches job and event location data from two separate API endpoints:
                      
                      http://localhost:8000/api/map-data (Jobs)
                      http://localhost:8000/api/events-map-data (Events)
                      Once the data is retrieved:
                      
                      It is filtered to include only locations that contain valid latitude and longitude.
                      Jobs and events are differentiated by their type property (job or event).
                      The data is stored in React state (useState) for rendering.
                      
                      Rendering the Map and Markers
                      Map Initialization uses useRef to maintain a reference to the Leaflet map.
                      Marker Handling:
                      The job markers and event markers are managed separately to allow filtering.
                      Leaflet.markercluster is used to group nearby markers dynamically.
                      A small jitter (randomized coordinate offset) is applied to avoid overlapping markers.
                      
                      Search & Layer Control
                      Leaflet GeoSearch allows users to search for locations within the map.
                      Layer Control enables toggling between job and event markers dynamically.
                      </p>
                    <h3>4.5 Statistics visualization</h3>
                    <p>The <code>EventStatisticsPage</code> component is a React-based data visualization page that presents event-related statistics using various charts and graphs. It fetches data from APIs and renders the insights dynamically.</p>

                    <h3>Technologies Used</h3>
                    <ul>
                        <li><strong>React</strong> - Frontend framework for building the UI.</li>
                        <li><strong>Chart.js</strong> - For rendering bar and pie charts.</li>
                        <li><strong>react-chartjs-2</strong> - React wrapper for Chart.js.</li>
                        <li><strong>Axios</strong> - For API calls.</li>
                        <li><strong>CalendarHeatmap</strong> - For rendering a heatmap representation of event density.</li>
                        <li><strong>schema-dts</strong> - Provides structured data in JSON-LD format for SEO optimization.</li>
                    </ul>

                    <h3>Data Flow</h3>
                    <h3>API Data Fetching</h3>
                    <p>The component uses <code>useEffect</code> to fetch data from multiple APIs upon mounting. The data is stored in React state variables using <code>useState</code>.</p>

                    <h4>APIs Used:</h4>
                    <ul>
                        <li><code>VITE_API_EVENTS_PER_TYPE</code> - Fetches event distribution by type.</li>
                        <li><code>VITE_API_EVENTS_IS_ONLINE</code> - Fetches online vs onsite event statistics.</li>
                        <li><code>VITE_API_EVENTS_PER_TOPIC</code> - Fetches events grouped by topic.</li>
                        <li><code>VITE_API_EVENTS_PER_DATE</code> - Fetches event occurrences over time.</li>
                        <li><code>VITE_API_EVENTS_PER_TECHNICAL_SKILL</code> - Fetches events by technical skill (programming languages, frameworks, libraries).</li>
                    </ul>

                    <h3>Component Structure</h3>
                    <pre><code>
                EventStatisticsPage
                ├── useEffect (fetchData)
                │   ├── Fetches data from APIs using Axios
                │   ├── Stores data in state variables
                │   ├── Handles API errors gracefully
                │
                ├── Pie Charts (Chart.js)
                │   ├── Events by Type
                │   ├── Online vs Onsite Events
                │
                ├── Bar Charts (Chart.js)
                │   ├── Events per Topic
                │   ├── Events per Technical Skill (Grouped by category)
                │
                ├── Calendar Heatmap
                │   ├── Displays event occurrences per date
                │
                ├── JSON-LD Metadata (SEO)
                    </code></pre>

                    <h2>Charts and Visualizations</h2>

                    <h3>Pie Charts</h3>
                    <ul>
                        <li><strong>Events Distribution by Type:</strong> Displays event counts categorized by type.</li>
                        <li><strong>Online vs Onsite Events:</strong> Differentiates between online and onsite events in Romania.</li>
                    </ul>

                    <h3>Bar Charts</h3>
                    <ul>
                        <li><strong>Events per Topic:</strong> Shows event counts per topic.</li>
                        <li><strong>Events per Technical Skill:</strong> Displays grouped bar charts for programming languages, frameworks, and libraries.</li>
                    </ul>

                    <h3>Calendar Heatmap</h3>
                    <p>Visualizes event density throughout the year, helping users identify high-activity periods.</p>

                    <h3>JSON-LD Metadata</h3>
                    <p>The component includes JSON-LD metadata for search engines to understand the statistical data catalog.</p>

                    <h4>Example JSON-LD Output:</h4>
                    <pre><code>{
                  "@context": "https://schema.org",
                  "@type": "DataCatalog",
                  "name": "IT events statistics",
                  "audience": "IT professionals and job seekers",
                  "dateCreated": "2025",
                  "inLanguage": "English",
                  "keywords": "IT, events, statistics, Romania",
                  "description": "Statistics on IT-related events in Romania and online."
                }</code></pre>
                <p>The component includes RDFa structured data for search engines to understand the statistical data catalog.</p>
                    <h3>4.7 Search events</h3>
                    <p>The <strong>Event Search Page</strong> is a React-based web component that allows users to search and filter IT-related events. Users can apply filters such as event type, topic, location, online status, and date.</p>

                  <h3>4.7.1. Technologies Used</h3>
                  <ul>
                      <li><strong>React</strong> - Frontend framework</li>
                      <li><strong>Axios</strong> - HTTP client for API calls</li>
                      <li><strong>React-Select</strong> - Multi-select dropdowns</li>
                      <li><strong>Schema.org JSON-LD</strong> - Structured data for SEO</li>
                      <li><strong>CSS</strong> - Custom styling</li>
                  </ul>

                  <h3>4.7.2. API Endpoints</h3>
                  <p>The component fetches data from the following APIs:</p>
                  <ul>
                      <li><code>VITE_API_EVENTS_TYPES</code> - Fetches available event types.</li>
                      <li><code>VITE_API_EVENTS_TOPICS</code> - Fetches available event topics.</li>
                      <li><code>VITE_API_EVENTS_LOCATIONS</code> - Fetches available event locations.</li>
                      <li><code>VITE_API_EVENTS</code> - Fetches events based on selected filters.</li>
                  </ul>

                  <h3>4.7.3 Component Functionality</h3>
                  <h3>State Management</h3>
                  <p>The component uses <code>useState</code> for managing filter options, selected values, and fetched event data.</p>
                  
                  <h3>Data Fetching</h3>
                  <p>Two main <code>useEffect</code> hooks are used:</p>
                  <ul>
                      <li>Fetching event filter options on page load.</li>
                      <li>Fetching events dynamically when filters change.</li>
                  </ul>

                  <h3>Event Filtering System</h3>
                  <p>The following filters can be applied:</p>
                  <ul>
                      <li><strong>Event Type</strong> - Multi-select dropdown</li>
                      <li><strong>Topic</strong> - Multi-select dropdown</li>
                      <li><strong>Location</strong> - Multi-select dropdown</li>
                      <li><strong>Online / Onsite</strong> - Single select (dropdown)</li>
                      <li><strong>Date</strong> - Date picker</li>
                  </ul>

                  <h3>JSON-LD Structured Data</h3>
                  <p>The page includes structured data for better search engine indexing.</p>
                  <pre><code>
                    {
                      "@context": "https://schema.org",
                      "@type": "WebPage",
                      "name": "Search Event Webpage",
                      "author": "Ciobanu Ana",
                      "inLanguage": "English",
                      "about": "A web page where users can search and filter IT-related events from Romania or online events.",
                      "datePublished": "2025-02-03",
                      "isPartOf": "Job Hunter Project",
                      "keywords": "IT events, Tech, Romania, Online Events"
                    }
                            </code></pre>
                    <h3>RDFa Structured Data</h3>
                    <p>The EventSearchPage component uses RDFa (Resource Description Framework in Attributes) as part of 
                      its structured data implementation. RDFa is embedded within HTML elements to help search engines and 
                      other applications better understand the content of the page. 
                      The RDFa markup uses Schema.org vocabulary to structure event data. Properties like name, about, location,
                       startDate, and eventAttendanceMode provide structured metadata for better indexing and search visibility.</p>
                    <h3>4.8 Events data fetch</h3>
                      <p>The event fetching program automates the extraction of IT-related events from a RSS feed and stores them
                         in the Apache Jena Fuseki triplestore.</p>
                  
                      <h3>4.8.1 Core Technologies Used</h3>
                      <ul>
                          <li><strong>Python</strong> - For data fetching and processing</li>
                          <li><strong>APScheduler</strong> - For scheduling daily event fetches</li>
                          <li><strong>Asyncio</strong> - For handling asynchronous operations</li>
                          <li><strong>BeautifulSoup</strong> - For parsing XML data from RSS feeds</li>
                          <li><strong>REST API</strong> - For inserting extracted events into the database</li>
                      </ul>
      
                      <h3>4.8.2 Scheduled RSS Fetching</h3>
                      <p>The script fetches events daily at midnight using the following scheduler:</p>
                      <pre><code>from apscheduler.schedulers.blocking import BlockingScheduler
              import asyncio
              from rss_feed_parser import rss_fetch_and_store_events
              
              def scheduled_rss_fetching():
                  loop = asyncio.new_event_loop()
                  asyncio.set_event_loop(loop)
                  loop.run_until_complete(rss_fetch_and_store_events())
              
              scheduler = BlockingScheduler()
              scheduler.add_job(scheduled_rss_fetching, 'cron', hour=0, minute=0)
              scheduler.start()</code></pre>
                      
                      <h3>4.8.3 RSS Data Extraction</h3>
                      <p>Data is extracted using <code>requests</code> and <code>BeautifulSoup</code>. Relevant fields include:</p>
                      <ul>
                          <li><strong>Event Title</strong></li>
                          <li><strong>Date</strong> (Extracted via regex)</li>
                          <li><strong>Location</strong> (City & Country identified if not online)</li>
                          <li><strong>Topic</strong> (Classified using <code>TechnicalSkillExtractor</code>)</li>
                          <li><strong>Event Type</strong></li>
                      </ul>
                      
                      <h3>4.8.4 Data Storage in Apache Jena Fuseki</h3>
                      <p>Extracted data is structured into JSON and sent to the API:</p>
                      <pre><code>event = {
                  "eventTitle": title,
                  "isOnline": str(isOnline),
                  "city": city if not isOnline else None,
                  "country": country if not isOnline else None,
                  "eventDate": f"{day}-{month}-{year}",
                  "eventURL": item.find("link").text,
                  "topic": categories[0],
                  "eventType": categories[1],
                  "topicCategory": topic_category,
                  "topicCategoryDetails": topic_category_details
              }
              requests.post(url, json=event)</code></pre>
                  </section>
                </section>
                <section id="conclusion">
                  <h2>Conclusions</h2>
                  <p>The project combine multiple components to provide a comprehensive solution for job seekers in the IT industry. It addresses the challenges of finding relevant IT-related events and job opportunities.
                    The user interface is user-friendly and easy to navigate, making it accessible to both individuals and organizations.
                    The backend infrastructure ensures efficient data processing and storage, while the data processing mechanisms optimize the user experience.
                  </p>
                </section>
                  <section typeof="sa:ReferenceList">
                    <h2>References</h2>
                    <p>
                      <ul>
                        <li  typeof="schema:WebPage"><a href="https://profs.info.uaic.ro/sabin.buraga/teach/courses/wade/index.html">Course Page, Sabin-Corneliu Buraga, 2025</a></li>
                        <li  typeof="schema:WebPage"><a href="https://skillner.vercel.app/">skillNer library</a></li>
                        <li  typeof="schema:WebPage"><a href="https://protege.stanford.edu/publications/ontology_development/ontology101.pdf">Ontology development in Protege</a></li>
                      </ul>
                </section>
        </article>
    </body>
</html>